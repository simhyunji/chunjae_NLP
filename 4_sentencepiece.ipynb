{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentencepiece : NSMC 데이터로 tokenizer 구성해보기\n",
    ": https://github.com/google/sentencepiece  \n",
    "\n",
    "내부 단어 분리를 위한 유용한 패키지: 구글의 센텐스피스(Sentencepiece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\chunjae\\appdata\\roaming\\python\\python311\\site-packages (0.1.99)\n"
     ]
    }
   ],
   "source": [
    "! pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sentencepiece as spm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 읽어오기 : ratings_train.txt\n",
    "\n",
    "train_df = pd.read_csv('data/ratings_train.csv')\n",
    "naver_df = pd.read_table('data/ratings_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "document    0\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null 값 제거 / 확인\n",
    "train_df.isnull().sum()\n",
    "train_df=train_df.dropna()\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id          0\n",
      "document    0\n",
      "label       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "naver_df = naver_df.dropna(how='any')\n",
    "print(naver_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149995\n"
     ]
    }
   ],
   "source": [
    "# 최종적으로 전처리된 텍스트를 'naver_review.txt'에 저장 (문장 \\n 구분)\n",
    "print(len(naver_df))\n",
    "with open('./data/naver_review.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(naver_df['document']))\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습하기: 2개 파일 생성 .vocab (subword), .model\n",
    "spm.SentencePieceTrainer.Train('--input=./data/naver_review.txt --model_prefix=naver --vocab_size=5000 --model_type=bpe --max_sentence_length=9999')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 코드는 SentencePiece를 사용하여 텍스트 데이터에서 Subword 기반의 언어 모델을 학습시키는 과정을 나타냅니다.\n",
    "\n",
    "여기서 각 매개변수의 역할은 다음과 같습니다:\n",
    "\n",
    "--input=./data/naver_review.txt: 학습에 사용할 텍스트 데이터의 경로를 지정합니다. 여기서는 \"./data/naver_review.txt\"에 해당합니다.\n",
    "--model_prefix=naver: 생성될 모델 파일의 접두사를 지정합니다. 여기서는 \"naver\"로 지정되어 있으므로 학습이 완료되면 \"naver.model\" 및 \"naver.vocab\" 파일이 생성됩니다.\n",
    "--vocab_size=5000: 어휘 크기를 지정합니다. 이것은 모델이 학습하는 서브워드의 수입니다. 여기서는 5000으로 지정되어 있으므로 5000개의 서브워드로 어휘를 구성하게 됩니다.\n",
    "--model_type=bpe: 서브워드 분할 방법을 지정합니다. 여기서는 BPE(Byte Pair Encoding) 방법을 사용합니다.\n",
    "--max_sentence_length=9999: 입력 문장의 최대 길이를 지정합니다. 여기서는 9999로 설정되어 있으므로 입력 문장의 최대 길이는 9999자입니다.\n",
    "이렇게 학습된 모델은 텍스트 데이터를 서브워드로 분할하여 어휘 사전을 구축하게 됩니다. 이후 이 모델을 사용하여 텍스트 데이터를 분할하거나 인코딩할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>..</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>영화</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>▁영화</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>▁이</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>▁아</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>...</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ᄏᄏ</td>\n",
       "      <td>-6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1\n",
       "0  <unk>  0\n",
       "1    <s>  0\n",
       "2   </s>  0\n",
       "3     ..  0\n",
       "4     영화 -1\n",
       "5    ▁영화 -2\n",
       "6     ▁이 -3\n",
       "7     ▁아 -4\n",
       "8    ... -5\n",
       "9     ᄏᄏ -6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab 파일 확인해보기\n",
    "vocab_list = pd.read_csv('./data/naver.vocab', sep='\\t', header=None, quoting=csv.QUOTE_NONE)\n",
    "vocab_list[:10]\n",
    "\n",
    "# 토큰과, 인덱스 번호\n",
    "# 영화라는 단어가 어디 있냐에 따라 _가 붙음 (영화가 중간에 나오면 _가 붙음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>▁프로</td>\n",
       "      <td>-1192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>밧</td>\n",
       "      <td>-4453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>▁이쁘</td>\n",
       "      <td>-1199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>▁앞으로</td>\n",
       "      <td>-2064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3478</th>\n",
       "      <td>년</td>\n",
       "      <td>-3475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>구려</td>\n",
       "      <td>-2479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4964</th>\n",
       "      <td>훠</td>\n",
       "      <td>-4961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4917</th>\n",
       "      <td>$</td>\n",
       "      <td>-4914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>▁열심히</td>\n",
       "      <td>-2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>▁연기자</td>\n",
       "      <td>-3195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0     1\n",
       "1195   ▁프로 -1192\n",
       "4456     밧 -4453\n",
       "1202   ▁이쁘 -1199\n",
       "2067  ▁앞으로 -2064\n",
       "3478     년 -3475\n",
       "2482    구려 -2479\n",
       "4964     훠 -4961\n",
       "4917     $ -4914\n",
       "2703  ▁열심히 -2700\n",
       "3198  ▁연기자 -3195"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 로드\n",
    "sp = spm.SentencePieceProcessor()\n",
    "vocab_file = './data/naver.model'\n",
    "sp.load(vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "털콩게 댄스댄스\n",
      "['▁', '털', '콩', '게', '▁', '댄', '스', '댄', '스']\n",
      "[3288, 4249, 3918, 3313, 3288, 4212, 3325, 4212, 3325]\n",
      "\n",
      "놀이동산 가고 싶어용 애옹 ㅋㅅㅋ\n",
      "['▁놀', '이', '동', '산', '▁가', '고', '▁싶어', '용', '▁애', '옹', '▁ᄏ', 'ᄉ', 'ᄏ']\n",
      "[577, 3290, 3384, 3659, 46, 3293, 3042, 3418, 144, 4134, 448, 3887, 3309]\n",
      "\n",
      "눈물 롬곡\n",
      "['▁눈물', '▁', '롬', '곡']\n",
      "[430, 3288, 4655, 3977]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델을 통해 tokenizing\n",
    "lines = [\n",
    "    \"털콩게 댄스댄스\",\n",
    "    \"놀이동산 가고 싶어용 애옹 ㅋㅅㅋ\",\n",
    "    \"눈물 롬곡\"\n",
    "]\n",
    "\n",
    "for line in lines:\n",
    "    print(line)\n",
    "    print(sp.encode_as_pieces(line)) # encoding to token\n",
    "    print(sp.encode_as_ids(line)) # encoding to idx\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델로 voca size 확인하기\n",
    "sp.GetPieceSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'털'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# id to subword\n",
    "sp.IdToPiece(4249)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4249"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subword to id\n",
    "sp.PieceToId('털')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'털콩게 댄스댄스'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ids to subwords\n",
    "sp.DecodeIds([3288, 4249, 3918, 3313, 3288, 4212, 3325, 4212, 3325])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'털콩게 댄스댄스'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subwords to 원형\n",
    "sp.DecodePieces(['▁', '털', '콩', '게', '▁', '댄', '스', '댄', '스'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁와', '웅', '▁', '털', '콩', '게', '!']\n",
      "[327, 3933, 3288, 4249, 3918, 3313, 3316]\n"
     ]
    }
   ],
   "source": [
    "# encode 메소드 중 out_type 인자를 통해: subwords, ids로 변환\n",
    "print(sp.encode('와웅 털콩게!', out_type=str))\n",
    "print(sp.encode('와웅 털콩게!', out_type=int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토크나이징 - konlp\n",
    "\n",
    "임베딩\n",
    "\n",
    "토크나이저로 이미 만들어져 있어서 그냥 로드해서 쓰면 됨\n",
    "\n",
    "llm 의 근간이 되는 모델 - 트랜스포머\n",
    "\n",
    "내일은 트랜스포머의 구조에 대해 배우면,\n",
    "\n",
    "버트는 왜 분류를 하는지, gpt 가 어떻게 대답을 하는지 알 수 있음\n",
    "\n",
    "이게 왜 필요하냐? 개념적으로 중요하기 때문에 구조를 세세하게 파악하는 것이 중요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
